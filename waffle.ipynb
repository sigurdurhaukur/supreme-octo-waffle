{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faiss and word2vec for fast semantic similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "! pip install faiss-cpu\n",
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download word2vec model (2.5GB)\n",
    "! curl --remote-name-all https://repository.clarin.is/repository/xmlui/bitstream/handle/20.500.12537/209{/word2vec_models.zip}\n",
    "! unzip /work/word2vec_models.zip\n",
    "! unzip -j /work/word2vec_models.zip '*READ*'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "vectors = KeyedVectors.load('./word2vec-isl/IGC_2021_lemmatized__350__13__9__5__0_05__1_vectors.kv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "store all the normalized data in a list, `xb` (for x database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(969714, 350)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb = vectors.get_normed_vectors()\n",
    "xb.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize the query `xq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 350)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "xq = vectors.get_vector('fingur', norm=True)\n",
    "xq = np.reshape(xq, (1, -1)).astype('float32')\n",
    "\n",
    "xq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "nlist = 128  # number of cells/clusters to partition data into\n",
    "d = 350      # dimension of vectors\n",
    "k = 10       # number of nearest neighbors to return\n",
    "\n",
    "quantizer = faiss.IndexFlatIP(d)  # how the vectors will be stored/compared\n",
    "index = faiss.IndexIVFFlat(quantizer, d, nlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.train(xb)  # we must train the index to cluster into cells\n",
    "\n",
    "# total words: 969714\n",
    "# last stable at: 484857 or 0.5*969714\n",
    "percent_of_total = 1*969_714\n",
    "\n",
    "index.add(xb[:484857])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.nprobe = 8  # how many nearest cells to search\n",
    "D, I = index.search(xq, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: fingur \n",
      "distance: 0.0 \n",
      "\n",
      "result: vísifingur \n",
      "distance: 0.609532356262207 \n",
      "\n",
      "result: putti \n",
      "distance: 0.6576252579689026 \n",
      "\n",
      "result: þumalfingur \n",
      "distance: 0.6648381352424622 \n",
      "\n",
      "result: þumall \n",
      "distance: 0.7613661885261536 \n",
      "\n",
      "result: langatöng \n",
      "distance: 0.7703074216842651 \n",
      "\n",
      "result: tá \n",
      "distance: 0.8249093294143677 \n",
      "\n",
      "result: handleggur \n",
      "distance: 0.8280805945396423 \n",
      "\n",
      "result: baugfingur \n",
      "distance: 0.8759332895278931 \n",
      "\n",
      "result: litlafingur \n",
      "distance: 0.8845452666282654 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# display results\n",
    "\n",
    "for i in range(len(I[0])):\n",
    "    distance = D[0][i] # small means most relevant\n",
    "    word_index = I[0][i]\n",
    "    try:\n",
    "        results = vectors.most_similar(positive=[vectors[word_index]], topn=1)\n",
    "        result_word = results[0][0]\n",
    "        print(f\"result: {result_word} \\ndistance: {distance} \\n\")\n",
    "    except: \n",
    "        print(\"something went wrong\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
